{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 api로 정보 받아오기\n",
    "client_id = \"aY4Gxe5F9WdX0P2JxiBz\" # 발급받은 id 입력\n",
    "client_secret = \"DMple3S42_\" # 발급받은 secret 입력 \n",
    "quote = input(\"검색어를 입력해주세요.: \") #검색어 입력받기\n",
    "encText = urllib.parse.quote(quote)\n",
    "display_num = input(\"검색 출력결과 갯수를 적어주세요.(최대100, 숫자만 입력): \") # 출력할 갯수 입력받기\n",
    "url = \"https://openapi.naver.com/v1/search/blog?query=\" + encText +\"&display=\"+display_num # json 결과\n",
    "\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-Naver-Client-Id\", \"aY4Gxe5F9WdX0P2JxiBz\")\n",
    "request.add_header(\"X-Naver-Client-Secret\", \"DMple3S42_\")\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    #print(response_body.decode('utf-8'))\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "\n",
    "body = response_body.decode('utf-8')\n",
    "body\n",
    "\n",
    "# 불필요한 \"\"(큰따옴표)지워주기\n",
    "body = body.replace('\"','')\n",
    "#print(body)\n",
    "\n",
    "#블로그 제목만 뽑기\n",
    "titles = re.findall('title: (.*?),\\nlink', body) #\\n은 엔터의 의미\n",
    "print('<<제목 모음>>')\n",
    "print(titles)\n",
    "print('총 제목 수: ',len(titles),'개')#제목갯수확인\n",
    "\n",
    "#블로그 링크들 추출\n",
    "links = re.findall('link: (.*?),\\ndescription',body)\n",
    "print('\\n<<링크 모음>>')\n",
    "print(links)\n",
    "print('총 링크 수: ',len(links),'개')#링크갯수확인\n",
    "\n",
    "# 제목 다듬기\n",
    "blog_titles = []\n",
    "for k in titles:\n",
    "    a = k.replace('<b>','')\n",
    "    b = a.replace('</b>', '')\n",
    "    blog_titles.append(b)\n",
    "\n",
    "# 링크를 다듬기 (필요없는 부분 제거 및 수정)\n",
    "blog_links = []\n",
    "for j in links:\n",
    "    print('링크: ',j)\n",
    "    if 'brunch' not in j: # brunch 블로그가 나오면 공백으로 남기기\n",
    "        a = j.replace('\\\\','')\n",
    "        b = a.replace('?Redirect=Log&logNo=','/')\n",
    "        blog_links.append(b)\n",
    "    else:\n",
    "        blog_links.append('')\n",
    "\n",
    "print(blog_links)\n",
    "print('생성된 링크 갯수:',len(blog_links),'개')\n",
    "\n",
    "\n",
    "#본문 크롤링\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\User\\\\Desktop\\\\fproject\\\\my_crawlingcode\\\\chromedriver.exe') #또는 driver.exe 가있는 파일 위치 복사하여 입력\n",
    "driver.implicitly_wait(4)\n",
    "\n",
    "# 블로그 링크 하나씩 불러서 크롤링\n",
    "contents = []\n",
    "for i in blog_links:\n",
    "    try:\n",
    "        # 블로그 링크 하나씩 불러오기\n",
    "        driver.get(i)\n",
    "        time.sleep(2)\n",
    "        # 블로그 안 본문이 있는 iframe에 접근하기\n",
    "        driver.switch_to.frame(\"mainFrame\")\n",
    "        # 본문 내용 크롤링하기\n",
    "        try:\n",
    "            a = driver.find_element_by_css_selector('div.se-main-container').text\n",
    "            contents.append(a)\n",
    "        except:  # NoSuchElement 오류시 예외처리(구버전 블로그에 적용)\n",
    "            a = driver.find_element_by_css_selector('div#content-area').text\n",
    "            contents.append(a)\n",
    "        # print(본문: \\n', a)\n",
    "    except: # brunch 블로그의 링크를 공백으로 예외처리\n",
    "        contents.append('')\n",
    "        continue\n",
    "\n",
    "# 창닫기\n",
    "driver.quit() \n",
    "print(\"<<본문 크롤링이 완료되었습니다.>>\")\n",
    "\n",
    "# 제목 및 본문 txt에 저장\n",
    "total_contents = titles + contents\n",
    "\n",
    "text = open(\"blog_text.txt\",'w',encoding='utf-8') \n",
    "for h in total_contents:\n",
    "    text.write(h)\n",
    "text.close()\n",
    "\n",
    "#제목, 블로그링크, 본문내용 Dataframe으로 만들기\n",
    "df = pd.DataFrame({'제목':blog_titles, '링크':blog_links,'내용':contents})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====접속 성공=====\n"
     ]
    }
   ],
   "source": [
    "conn_str = 'host=localhost dbname=naver_blog user=postgres password=1234 port=5432'\n",
    "try: \n",
    "    conn = psycopg2.connect(conn_str)\n",
    "    print('=====접속 성공=====')\n",
    "except psycopg2.DatabaseError as db_err:\n",
    "    print('접속오류!!')\n",
    "    print(db_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커서 생성\n",
    "cur = conn.cursor()\n",
    "\n",
    "# engine 생성\n",
    "engine = create_engine('postgresql://postgres:1234@localhost:5432/naver_blog')\n",
    "\n",
    "# 실행할 때마다 다른 값이 나오지 않게 테이블 제거\n",
    "cur.execute('DROP TABLE IF EXISTS naver_blog')\n",
    "\n",
    "df.to_sql(name='blogcrawling',\n",
    "        con = engine,\n",
    "        schema='public',\n",
    "        if_exists='replace', # {'fail', 'replace', 'append'}, dafault : 'fail'\n",
    "        index= True,\n",
    "        index_label='id',\n",
    "        chunksize= 100,\n",
    "        dtype= {\n",
    "            'id' : sqlalchemy.types.INTEGER(),\n",
    "            '제목' : sqlalchemy.types.VARCHAR(200),\n",
    "            '링크' : sqlalchemy.types.VARCHAR(200),\n",
    "            '내용' : sqlalchemy.types.VARCHAR(10000),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 csv파일로 저장\n",
    "df.to_csv('df_1.csv', index=False, header=False, encoding='utf-8-sig') # encoding='utf-8-sig' : 크롤링 후 csv에 저장할 때"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
