{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 정규화\n",
    "def kor(text):\n",
    "    한글 = '[^가-힣ㄱ-ㅎㅏ-ㅢ]'\n",
    "    result = re.sub(한글, '', str(text))\n",
    "    result.strip()\n",
    "    return result\n",
    "\n",
    "# 맞춤법 검사\n",
    "from hanspell import spell_checker\n",
    "\n",
    "# 맞춤법\n",
    "import requests, ast\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# hanspell 실행 관련 문제가 많이 발생하기 때문에 hanspell에서 구현한 방법 중 일부를 차용하여 함수를 구성합니다.\n",
    "def spell_check(text):\n",
    "    result = None\n",
    "    with requests.Session() as req:\n",
    "        base_url= 'https://m.search.naver.com/p/csearch/ocontent/spellchecker.nhn'\n",
    "        payload = {\n",
    "            '_callback':'window.__jindo2_callback._spellingCheck_0',\n",
    "            'q': text\n",
    "        }\n",
    "        headers = {\n",
    "            'referer': 'https://search.naver.com/',\n",
    "            'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'\n",
    "        }\n",
    "        result = req.get(base_url, params=payload, headers = headers).text\n",
    "        _from = result.index('(')+1\n",
    "        _to = len(result) - (result[::-1].index(')')) - 1\n",
    "        result = ast.literal_eval(result[_from:_to])['message']['result']\n",
    "    output = {k:bs(v, 'lxml').text for k,v in result.items() if isinstance(v, str)}\n",
    "    return output['html']\n",
    "\n",
    "### 맞춤법 + 예외처리 ###\n",
    "def correction(text, exceptions=[]):\n",
    "    dic = {excp:f'<<<{i}>>>' for i,excp in enumerate(exceptions)}\n",
    "    inv_dic = {v:k for k,v in dic.items()}\n",
    "    for k,v in dic.items():\n",
    "        text = text.replace(k,v)\n",
    "        # 눈<은>, <은>의 가격\n",
    "        #'(?<=[가-힣])은'\n",
    "        #text = re.sub(k,v,text)\n",
    "    text = spell_check(text)\n",
    "    for k,v in inv_dic.items():\n",
    "        text = text.replace(k,v)\n",
    "    return text\n",
    "\n",
    "\n",
    "##### 반복되는 문자 제거 ######\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "def repeat(text):\n",
    "    new_text = emoticon_normalize(text, num_repeats = 2)\n",
    "    return new_text\n",
    "\n",
    "##### 입력 오타 수정기 ######\n",
    "\n",
    "def jamo_merge(jamolist):\n",
    "    consonant = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    vowel = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "    final_consonant = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ',\n",
    "                       'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "    a,b,c = jamolist\n",
    "    if (a in consonant) and (b in vowel) and (c in final_consonant):\n",
    "        c, v, f_c = [ _list.index(j) for _list, j in zip([consonant,vowel,final_consonant],jamolist)]\n",
    "        return chr(f_c + 588 * c + 28 * v + ord('가'))\n",
    "    else:\n",
    "        result = ' '.join(jamolist)\n",
    "        result = ' ' if result.strip()=='' else result.strip()\n",
    "        return result\n",
    "\n",
    "def jamo_split(char):\n",
    "    consonant = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    vowel = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "    final_consonant = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ',\n",
    "                       'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    base = ord(char) - ord('가')\n",
    "    c = base // 588\n",
    "    v = (base - 588 * c) // 28\n",
    "    f_c = base - 588 * c - 28 * v\n",
    "    return [consonant[c], vowel[v], final_consonant[f_c]]\n",
    "\n",
    "\n",
    "## 이거 찐 ##\n",
    "def jamo_correction(text):\n",
    "    consonant,vowel = (12593, 12622),(12623,12686) #각각 자음, 모음의 범위\n",
    "    merged = (44032, 55203) #<가-힣>까지의 조합된 한글의 범위\n",
    "    isin = lambda c, nrange: c >= nrange[0] and c <= nrange[1]  \n",
    "    result = [[]]\n",
    "    text = text+' '\n",
    "    for i in range(len(text.strip())):\n",
    "        if not isin(ord(text[i]), merged):\n",
    "            if isin(ord(text[i]), vowel) and len(result[-1])==1:\n",
    "                result[-1].append(text[i])\n",
    "            elif isin(ord(text[i]), consonant) and result[-1][-1]==' ' and len(result[-1])==3:\n",
    "                if isin(ord(text[i+1]), merged):\n",
    "                    result[-1][-1] = text[i]\n",
    "                else:\n",
    "                    result.append([text[i]])\n",
    "            else:\n",
    "                result.append([])\n",
    "                result[-1].append(text[i])\n",
    "        else:\n",
    "            result.append(jamo_split(text[i]))\n",
    "    result = result[1:]\n",
    "    output = [[' ' for i in range(3)] for j in range(len(result))]\n",
    "    for i in range(len(output)):\n",
    "        output[i][:len(result[i])]= result[i]        \n",
    "    output = list(map(jamo_merge, output))\n",
    "    return ''.join(output)\n",
    "\n",
    "\n",
    "##### 고유 명사 예외처리 ######\n",
    "\n",
    "# import pandas as pd\n",
    "# path = './NIADic.xlsx' \n",
    "# df_new = pd.read_excel(path)\n",
    "# df_new1 = df_new.loc[(df_new.category=='people_names')]\n",
    "# df_new2 = df_new.loc[(df_new.category=='brand_name')]\n",
    "# df_new3 = df_new.loc[(df_new.category=='proper_noun')]\n",
    "# total = pd.concat([df_new1,df_new2,df_new3], ignore_index=True, sort=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dic_result = {'terms': total['term'].values.tolist()}\n",
    "# with open('./data/proper_noun.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(dic_result, f)\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import requests\n",
    "from itertools import *\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from hanspell import spell_checker\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "class Corrector(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        with open('./고유명사.json', 'r', encoding='utf-8') as r:\n",
    "            self.proper_nouns = json.load(r)['terms']\n",
    "        \n",
    "        self.consonant = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "        self.vowel = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "        self.final_consonant = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ',\n",
    "                           'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "    def remove_repeat(self, text, repeat=2):\n",
    "        result = [[]]\n",
    "        for t in text:\n",
    "            if (t in result[-1]) and not (ord('가')<=ord(t)<=ord('힣')):\n",
    "                result[-1].append(t)\n",
    "            else:\n",
    "                result.append([t])\n",
    "        result = list(chain(*map(lambda x: x[:repeat], result[1:])))\n",
    "        return ''.join(result)\n",
    "        \n",
    "    def merge_hangul(self, text):\n",
    "        consonant,vowel = (12593, 12622),(12623,12686) #각각 자음, 모음의 범위\n",
    "        merged = (44032, 55203) #<가-힣>까지의 조합된 한글의 범위\n",
    "        isin = lambda c, nrange: c >= nrange[0] and c <= nrange[1]  \n",
    "        result = [[]]\n",
    "        text = text+' '\n",
    "        for i in range(len(text.strip())):\n",
    "            if not isin(ord(text[i]), merged):\n",
    "                if isin(ord(text[i]), vowel) and len(result[-1])==1:\n",
    "                    result[-1].append(text[i])\n",
    "                elif isin(ord(text[i]), consonant) and result[-1][-1]==' ' and len(result[-1])==3:\n",
    "                    if isin(ord(text[i+1]), merged):\n",
    "                        result[-1][-1] = text[i]\n",
    "                    else:\n",
    "                        result.append([text[i]])\n",
    "                else:\n",
    "                    result.append([])\n",
    "                    result[-1].append(text[i])\n",
    "            else:\n",
    "                result.append(self._jamo_split(text[i]))\n",
    "        result = result[1:]\n",
    "        output = [[' ' for i in range(3)] for j in range(len(result))]\n",
    "        for i in range(len(output)):\n",
    "            output[i][:len(result[i])]= result[i]        \n",
    "        output = list(map(self._jamo_merge, output))\n",
    "        return ''.join(output)\n",
    "    \n",
    "    def _jamo_split(self, char):\n",
    "        base = ord(char) - ord('가')\n",
    "        c = base // 588\n",
    "        v = (base - 588 * c) // 28\n",
    "        f_c = base - 588 * c - 28 * v\n",
    "        return [self.consonant[c], self.vowel[v], self.final_consonant[f_c]]\n",
    "    \n",
    "    def _jamo_merge(self, jamolist):\n",
    "        a,b,c = jamolist\n",
    "        if (a in self.consonant) and (b in self.vowel) and (c in self.final_consonant):\n",
    "            c, v, f_c = [ _list.index(j) for _list, j in zip([self.consonant,self.vowel,self.final_consonant],jamolist)]\n",
    "            return chr(f_c + 588 * c + 28 * v + ord('가'))\n",
    "        else:\n",
    "            result = ' '.join(jamolist)\n",
    "            result = ' ' if result.strip()=='' else result.strip()\n",
    "            return result\n",
    "    \n",
    "    def spell_check(self,text):\n",
    "        result = None\n",
    "        with requests.Session() as req:\n",
    "            base_url= 'https://m.search.naver.com/p/csearch/ocontent/spellchecker.nhn'\n",
    "            payload = {\n",
    "                '_callback':'window.__jindo2_callback._spellingCheck_0',\n",
    "                'q': text\n",
    "            }\n",
    "            headers = {\n",
    "                'referer': 'https://search.naver.com/',\n",
    "                'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'\n",
    "            }\n",
    "            result = req.get(base_url, params=payload, headers = headers).text\n",
    "            _from = result.index('(')+1\n",
    "            _to = len(result) - (result[::-1].index(')')) - 1\n",
    "            result = ast.literal_eval(result[_from:_to])['message']['result']\n",
    "        output = {k:bs(v, 'lxml').text for k,v in result.items() if isinstance(v, str)}\n",
    "        return output\n",
    "\n",
    "\n",
    "    \n",
    "    def masking_exception(self, text, exceptions=[]):\n",
    "        masked = []\n",
    "        origins = []\n",
    "        tokens = self.tokenize(text)\n",
    "        for token in tokens:\n",
    "            if token in exceptions:\n",
    "                origins.append(token)\n",
    "                token = '<MASK>'\n",
    "            masked.append(token)\n",
    "        return masked, origins\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        output_tokens = []\n",
    "        for token in text.split():\n",
    "            sub_tokens = self.sub_tokenize(token)\n",
    "            output_tokens += sub_tokens\n",
    "            output_tokens.append(' ')\n",
    "        return output_tokens\n",
    "\n",
    "    def sub_tokenize(self, text):\n",
    "        post_position = ['이','가','을','를','는','로','의', '입니다','입니다.', '습니다'] # 더 많이 있지만 예시를 위해 이 정도로 제한\n",
    "        expression = '({})$'.format('|'.join(post_position))\n",
    "        sub_tokens = re.split(expression,text)\n",
    "        sub_tokens = [t for t in sub_tokens if t!='']\n",
    "        return sub_tokens\n",
    "\n",
    "    def correct(self, text, n_repeat=1):\n",
    "        text = self.remove_repeat(text, n_repeat)\n",
    "        text = self.merge_hangul(text)\n",
    "        textlist, origin_words = self.masking_exception(text, self.proper_nouns)\n",
    "        text = ' '.join(textlist)\n",
    "        text = self.spell_check(text)['html']\n",
    "        text = text.split()\n",
    "        for word in origin_words:\n",
    "            for i,token in enumerate(text):\n",
    "                if token.find('<MASK>')!=-1:\n",
    "                    strt = token.index('<MASK>')\n",
    "                    text[i] = token[:strt]+word+token[strt+len('<MASK>'):]\n",
    "        return ' '.join(text)\n",
    "\n",
    "corrector = Corrector()\n",
    "# corrector.correct('잇몸이 튼튼해지는 듯요 입안도 개운하고요')\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "def remove_repeat(text, repeat=1):\n",
    "    result = [[]]\n",
    "    for t in text:\n",
    "        if (t in result[-1]) and not (ord('가')<=ord(t)<=ord('힣')):\n",
    "            result[-1].append(t)\n",
    "        else:\n",
    "            result.append([t])\n",
    "    result = list(chain(*map(lambda x: x[:repeat], result[1:])))\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>내용</th>\n",
       "      <th>날짜</th>\n",
       "      <th>수정</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>잇몸이 튼튼해지는 듯요. 입안도 개운하고요.~</td>\n",
       "      <td>NaN</td>\n",
       "      <td>잇몸이튼튼해지는듯요입안도개운하고요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>자주쓰는 치약이에요 좋아요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>자주쓰는치약이에요좋아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>늘 사용하는 제품 저렴하게 구매했네요\\n상쾌하고 압안이 개운해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>늘사용하는제품저렴하게구매했네요상쾌하고압안이개운해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>아침에 일어나면 입냄새가 나지 안아서 좋아요 텁텁함도 없구요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>아침에일어나면입냄새가나지안아서좋아요텁텁함도없구요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>초2 아들도 이 치약만 써요.\\n양치하고나서 개운해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>초아들도이치약만써요양치하고나서개운해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29978</th>\n",
       "      <td>사업자 반값구매 혜택 좋네요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>사업자반값구매혜택좋네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29979</th>\n",
       "      <td>잘쓸개요 충치야 생기지마라</td>\n",
       "      <td>NaN</td>\n",
       "      <td>잘쓸개요충치야생기지마라</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29980</th>\n",
       "      <td>배송빠르고 상품조아요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>배송빠르고상품조아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29981</th>\n",
       "      <td>치약 한참 쓰겠네요...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>치약한참쓰겠네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29982</th>\n",
       "      <td>저렴하게 잘 샀네요.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>저렴하게잘샀네요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29983 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        내용  날짜                           수정\n",
       "0                잇몸이 튼튼해지는 듯요. 입안도 개운하고요.~ NaN           잇몸이튼튼해지는듯요입안도개운하고요\n",
       "1                           자주쓰는 치약이에요 좋아요 NaN                 자주쓰는치약이에요좋아요\n",
       "2      늘 사용하는 제품 저렴하게 구매했네요\\n상쾌하고 압안이 개운해요 NaN  늘사용하는제품저렴하게구매했네요상쾌하고압안이개운해요\n",
       "3        아침에 일어나면 입냄새가 나지 안아서 좋아요 텁텁함도 없구요 NaN   아침에일어나면입냄새가나지안아서좋아요텁텁함도없구요\n",
       "4            초2 아들도 이 치약만 써요.\\n양치하고나서 개운해요 NaN         초아들도이치약만써요양치하고나서개운해요\n",
       "...                                    ...  ..                          ...\n",
       "29978                      사업자 반값구매 혜택 좋네요 NaN                 사업자반값구매혜택좋네요\n",
       "29979                       잘쓸개요 충치야 생기지마라 NaN                 잘쓸개요충치야생기지마라\n",
       "29980                          배송빠르고 상품조아요 NaN                   배송빠르고상품조아요\n",
       "29981                        치약 한참 쓰겠네요... NaN                     치약한참쓰겠네요\n",
       "29982                          저렴하게 잘 샀네요. NaN                     저렴하게잘샀네요\n",
       "\n",
       "[29983 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = pd.read_csv('./치약 리뷰 총합.csv')\n",
    "review['수정'] = review['내용'].apply(lambda x:kor(x))\n",
    "\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aaa(text):\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = []\n",
    "for i in range(0, 29883):\n",
    "    try:\n",
    "        gb.append(correction(review['수정'].iloc[i], exceptions = []))\n",
    "    except:\n",
    "        gb.append('')\n",
    "gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review.loc[:, '수정2'] = gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review['수정2'] = review['수정2'].apply(lambda x:remove_repeat(x, repeat=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review['수정2'] = review['수정2'].apply(lambda x:jamo_correction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review.to_csv('./문제.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50f792c232382dd8182a4468ee26737522599fd0da1dfe4c48ed34f0951b738f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
